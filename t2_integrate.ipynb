{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data integration\n",
    "\n",
    "For each sub-dataset, write (and execute) code that converts a file (using possibly an old schema) into a file that has the new, latest schema version.\n",
    "\n",
    "Your conversion code should not modify the original files, but instead create a new file. Be sure to explain the design behind your conversion functions!\n",
    "\n",
    "The data integration step is highly parallellizable. Therefore, your solution on this part\n",
    "**must** be written in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: this notebook assumes that:\n",
    "\n",
    "- The data are in \"MY_PARENT_FOLDER/data/sampled/\" folder. You can run the bash script \"download_metadata.sh\" to download data and metadata in the correct folders to execute the jupyter notebooks.\n",
    "- The data are sampled to be run on a personnal computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark application already started. Terminating existing application and starting new one\n"
     ]
    }
   ],
   "source": [
    "# Imports go here\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os \n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=3g  pyspark-shell\"\n",
    "from pyspark.sql import SparkSession\n",
    "try: \n",
    "    spark\n",
    "    print(\"Spark application already started. Terminating existing application and starting new one\")\n",
    "    spark.stop()\n",
    "except: \n",
    "    pass\n",
    "# Create a new spark session (note, the * indicates to use all available CPU cores)\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"H600 L-Group\") \\\n",
    "    .getOrCreate()\n",
    "#When dealing with RDDs, we work the sparkContext object. See https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext\n",
    "sc=spark.sparkContext\n",
    "#in local mode, you will be able to access the Spark GUI at http://localhost:4040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory data/t2 failed\n",
      "Creation of the directory data/t2/yellow failed\n",
      "Creation of the directory data/t2/green failed\n",
      "Creation of the directory data/t2/fhv failed\n",
      "Creation of the directory data/t2/fhvhv failed\n"
     ]
    }
   ],
   "source": [
    "#create t2 directories\n",
    "try:\n",
    "    os.mkdir(\"data/t2\")\n",
    "except OSError:\n",
    "    print (\"Creation of the directory data/t2 failed\")\n",
    "else:\n",
    "    print (\"Successfully created the directory data/t2\")\n",
    "\n",
    "list_taxi = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
    "#list_taxi = [\"green\"]\n",
    "for taxi_brand in list_taxi :\n",
    "    path = \"data/t2/%s\" %(taxi_brand)\n",
    "    # List the file from the same taxi company brand \n",
    "    try:\n",
    "        os.mkdir(path)  \n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FHVHV files\n",
    "\n",
    "From previous analyses we saw that header was consistent across all then fhvhv files.\n",
    "We can then create a unified file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of fhvhv tripdata files:\n",
      "fhvhv_tripdata_2019-02.csv  fhvhv_tripdata_2020-01.csv\n",
      "fhvhv_tripdata_2019-03.csv  fhvhv_tripdata_2020-03.csv\n",
      "fhvhv_tripdata_2019-04.csv  fhvhv_tripdata_2020-04.csv\n",
      "fhvhv_tripdata_2019-05.csv  fhvhv_tripdata_2020-05.csv\n",
      "fhvhv_tripdata_2019-06.csv  fhvhv_tripdata_2020-06.csv\n",
      "count of fhvhv tripdata files:\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#export new csv file\n",
    "#fhvhv_DF.write.save(path='data/modified/fhvhv.csv', format='csv', mode='append', sep='\\t')\n",
    "#Ã§a fait un dossier ac plusieurs fichiers pourris\n",
    "\n",
    "#move files to t2 directory\n",
    "source_dir= 'data/sampled/'       \n",
    "for filename in glob.glob(os.path.join(source_dir,'fhvhv_*.csv')):\n",
    "    shutil.copy(filename, 'data/t2/fhvhv')\n",
    "\n",
    "print ('list of fhvhv tripdata files:')\n",
    "!ls data/t2/fhvhv\n",
    "\n",
    "print ('count of fhvhv tripdata files:')\n",
    "!find data/t2/fhvhv -type f | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.FHV files\n",
    "\n",
    "From previous analyses we saw that for fhv there are some adjustements:\n",
    "\n",
    "In 2017 - 1 :\n",
    "\n",
    "4 diff on a total of 5 col: ['pickup_datetime', 'dropoff_datetime', 'pulocationid', 'dolocationid']\n",
    "           2/4 col add\n",
    "           2/4 name change\n",
    "\n",
    "In 2017 - 7 :\n",
    "\n",
    "1 diff on a total of 6 col: ['sr_flag']\n",
    "           1/1 col add\n",
    "\n",
    "In 2018 - 1 :\n",
    "\n",
    "1 diff on a total of 7 col: ['dispatching_base_number']\n",
    "           1/1 col add\n",
    "\n",
    "In 2019 - 1 :\n",
    "\n",
    "1 diff on a total of 6 col: ['dispatching_base_number']\n",
    "           1/1 col remove\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of fhv tripdata files:\n",
      "data/sampled/fhv_tripdata_2015-01.csv  data/sampled/fhv_tripdata_2017-09.csv\r\n",
      "data/sampled/fhv_tripdata_2015-02.csv  data/sampled/fhv_tripdata_2017-10.csv\r\n",
      "data/sampled/fhv_tripdata_2015-03.csv  data/sampled/fhv_tripdata_2017-11.csv\r\n",
      "data/sampled/fhv_tripdata_2015-04.csv  data/sampled/fhv_tripdata_2017-12.csv\r\n",
      "data/sampled/fhv_tripdata_2015-05.csv  data/sampled/fhv_tripdata_2018-01.csv\r\n",
      "data/sampled/fhv_tripdata_2015-06.csv  data/sampled/fhv_tripdata_2018-02.csv\r\n",
      "data/sampled/fhv_tripdata_2015-07.csv  data/sampled/fhv_tripdata_2018-03.csv\r\n",
      "data/sampled/fhv_tripdata_2015-08.csv  data/sampled/fhv_tripdata_2018-04.csv\r\n",
      "data/sampled/fhv_tripdata_2015-09.csv  data/sampled/fhv_tripdata_2018-05.csv\r\n",
      "data/sampled/fhv_tripdata_2015-10.csv  data/sampled/fhv_tripdata_2018-06.csv\r\n",
      "data/sampled/fhv_tripdata_2015-11.csv  data/sampled/fhv_tripdata_2018-07.csv\r\n",
      "data/sampled/fhv_tripdata_2015-12.csv  data/sampled/fhv_tripdata_2018-08.csv\r\n",
      "data/sampled/fhv_tripdata_2016-01.csv  data/sampled/fhv_tripdata_2018-09.csv\r\n",
      "data/sampled/fhv_tripdata_2016-02.csv  data/sampled/fhv_tripdata_2018-10.csv\r\n",
      "data/sampled/fhv_tripdata_2016-03.csv  data/sampled/fhv_tripdata_2018-11.csv\r\n",
      "data/sampled/fhv_tripdata_2016-04.csv  data/sampled/fhv_tripdata_2018-12.csv\r\n",
      "data/sampled/fhv_tripdata_2016-05.csv  data/sampled/fhv_tripdata_2019-01.csv\r\n",
      "data/sampled/fhv_tripdata_2016-06.csv  data/sampled/fhv_tripdata_2019-02.csv\r\n",
      "data/sampled/fhv_tripdata_2016-07.csv  data/sampled/fhv_tripdata_2019-03.csv\r\n",
      "data/sampled/fhv_tripdata_2016-08.csv  data/sampled/fhv_tripdata_2019-04.csv\r\n",
      "data/sampled/fhv_tripdata_2016-09.csv  data/sampled/fhv_tripdata_2019-05.csv\r\n",
      "data/sampled/fhv_tripdata_2016-10.csv  data/sampled/fhv_tripdata_2019-06.csv\r\n",
      "data/sampled/fhv_tripdata_2016-11.csv  data/sampled/fhv_tripdata_2019-07.csv\r\n",
      "data/sampled/fhv_tripdata_2016-12.csv  data/sampled/fhv_tripdata_2019-08.csv\r\n",
      "data/sampled/fhv_tripdata_2017-01.csv  data/sampled/fhv_tripdata_2019-09.csv\r\n",
      "data/sampled/fhv_tripdata_2017-02.csv  data/sampled/fhv_tripdata_2019-10.csv\r\n",
      "data/sampled/fhv_tripdata_2017-03.csv  data/sampled/fhv_tripdata_2019-11.csv\r\n",
      "data/sampled/fhv_tripdata_2017-04.csv  data/sampled/fhv_tripdata_2020-01.csv\r\n",
      "data/sampled/fhv_tripdata_2017-05.csv  data/sampled/fhv_tripdata_2020-03.csv\r\n",
      "data/sampled/fhv_tripdata_2017-06.csv  data/sampled/fhv_tripdata_2020-04.csv\r\n",
      "data/sampled/fhv_tripdata_2017-07.csv  data/sampled/fhv_tripdata_2020-05.csv\r\n",
      "data/sampled/fhv_tripdata_2017-08.csv  data/sampled/fhv_tripdata_2020-06.csv\r\n"
     ]
    }
   ],
   "source": [
    "#source_dir= 'data/sampled/'       \n",
    "#or filename in glob.glob(os.path.join(source_dir,'fhv_*.csv')):\n",
    "#   shutil.copy(filename, 'data/t2/fhv')\n",
    "\n",
    "print ('list of fhv tripdata files:')\n",
    "!ls data/sampled/fhv_*\n",
    "\n",
    "#rint ('count of fhv tripdata files:')\n",
    "#find data/t2/fhv -type f | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pickup_DateTime: timestamp (nullable = true)\n",
      " |-- DropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Dispatching_base_number: string (nullable = true)\n",
      " |-- Dispatching_base_num: string (nullable = true)\n",
      "\n",
      "+-------------------+-------------------+------------+------------+-------+-----------------------+--------------------+\n",
      "|    Pickup_DateTime|   DropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Dispatching_base_number|Dispatching_base_num|\n",
      "+-------------------+-------------------+------------+------------+-------+-----------------------+--------------------+\n",
      "|2018-01-20 20:07:22|2018-01-20 20:16:51|          62|          17|      1|                 B02510|                null|\n",
      "+-------------------+-------------------+------------+------------+-------+-----------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      "\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|              B02872|2019-01-23 09:17:46|2019-01-23 09:44:21|         181|         137|   null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read fhv files\n",
    "#fhv1_DF = (spark.read\n",
    "#           .option(\"sep\", \",\")\n",
    "#           .option(\"header\", True)\n",
    "#           .option(\"inferSchema\", True)\n",
    "#            .csv('data/sampled/fhv_tripdata_2015-01.csv'))\n",
    "#fhv1_DF.printSchema()\n",
    "#fhv1_DF.show(1)\n",
    "#fhv2_DF = (spark.read\n",
    "#           .option(\"sep\", \",\")\n",
    "#           .option(\"header\", True)\n",
    "#           .option(\"inferSchema\", True)\n",
    "#            .csv('data/sampled/fhv_tripdata_2017-01.csv'))\n",
    "#fhv2_DF.printSchema()\n",
    "##fhv2_DF.show(1)\n",
    "#fhv3_DF = (spark.read\n",
    "#           .option(\"sep\", \",\")\n",
    "#           .option(\"header\", True)\n",
    "#           .option(\"inferSchema\", True)\n",
    "#            .csv('data/sampled/fhv_tripdata_2017-07.csv'))\n",
    "#fhv3_DF.printSchema()\n",
    "#fhv3_DF.show(1)\n",
    "fhv4_DF = (spark.read\n",
    "           .option(\"sep\", \",\")\n",
    "           .option(\"header\", True)\n",
    "           .option(\"inferSchema\", True)\n",
    "            .csv('data/sampled/fhv_tripdata_2018-01.csv'))\n",
    "fhv4_DF.printSchema()\n",
    "fhv4_DF.show(1)\n",
    "fhv5_DF = (spark.read\n",
    "           .option(\"sep\", \",\")\n",
    "           .option(\"header\", True)\n",
    "           .option(\"inferSchema\", True)\n",
    "            .csv('data/sampled/fhv_tripdata_2019-01.csv'))\n",
    "fhv5_DF.printSchema()\n",
    "fhv5_DF.show(1)\n",
    "\n",
    "#avant 01/2015 il faut ajouter |dropoff_datetime||DOLocationID|SR_Flag\n",
    "# modifier Pickup_date en pickup_datetime, locationID en PULocationID, Dispatching_base_num en dispatching_base_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+----------------+------------+------------+-------+\n",
      "|              B02764|2015-01-09 23:28:06|            null|         186|        null|   null|\n",
      "+--------------------+-------------------+----------------+------------+------------+-------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------+-------------------+----------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+----------------+------------+------------+-------+\n",
      "|              B02914|2017-01-19 22:09:39|            null|        null|        null|   null|\n",
      "+--------------------+-------------------+----------------+------------+------------+-------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|              B02879|2017-07-10 06:35:56|2017-07-10 06:45:17|         249|         163|   null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|                null|2018-01-20 20:07:22|2018-01-20 20:16:51|          62|          17|      1|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "#file_name='fhv_tripdata_2015-01.csv'\n",
    "#source_dir= 'data/sampled/' \n",
    "#dest_dir='data/t2/fhv'\n",
    "\n",
    "#1.modifing schema as needed\n",
    "fhv_201501 = fhv1_DF.withColumn(\"dropoff_datetime\",lit('null'))\\\n",
    "                    .withColumn(\"DOLocationID\",lit('null'))\\\n",
    "                    .withColumn(\"SR_Flag\",lit('null'))\\\n",
    "                    .select(\n",
    "                        col(\"Dispatching_base_num\").alias(\"dispatching_base_num\"),\n",
    "                        col(\"Pickup_date\").alias(\"pickup_datetime\"),\n",
    "                        \"dropoff_datetime\",\n",
    "                        col(\"locationID\").alias(\"PULocationID\"),\n",
    "                        \"DOLocationID\",\n",
    "                        \"SR_Flag\")\n",
    "fhv_201501.show(1)\n",
    "#saving new file                                     \n",
    "#export new csv file\n",
    "#fhv_201501.write.save(path='data/t2/fhv/fhv_tripdata_2015-01.csv', format='csv', mode='append', sep=',')\n",
    "#print ('list of fhv tripdata files:')\n",
    "#!ls data/t2/fhv\n",
    "\n",
    "#2.modifing schema as needed\n",
    "fhv_201701 = fhv2_DF.withColumn(\"DOLocationID\",lit('null'))\\\n",
    "                    .withColumn(\"SR_Flag\",lit('null'))\\\n",
    "                    .select(\n",
    "                        col(\"Dispatching_base_num\").alias(\"dispatching_base_num\"),\n",
    "                        col(\"Pickup_DateTime\").alias(\"pickup_datetime\"),\n",
    "                        col(\"Dropoff_datetime\").alias(\"dropoff_datetime\"),\n",
    "                        \"PULocationID\",\n",
    "                        \"DOLocationID\",\n",
    "                        \"SR_Flag\")\n",
    "fhv_201701.show(1)\n",
    "#3.modifing schema as needed\n",
    "fhv_201707 = fhv3_DF.select(\n",
    "                        col(\"Dispatching_base_num\").alias(\"dispatching_base_num\"),\n",
    "                        col(\"Pickup_DateTime\").alias(\"pickup_datetime\"),\n",
    "                        col(\"Dropoff_datetime\").alias(\"dropoff_datetime\"),\n",
    "                        \"PULocationID\",\n",
    "                        \"DOLocationID\",\n",
    "                        \"SR_Flag\")\n",
    "fhv_201707.show(1)\n",
    "#4.modifing schema as needed\n",
    "fhv_201801 =  fhv4_DF.select(\n",
    "                        col(\"Dispatching_base_num\").alias(\"dispatching_base_num\"),\n",
    "                        col(\"Pickup_DateTime\").alias(\"pickup_datetime\"),\n",
    "                        col(\"Dropoff_datetime\").alias(\"dropoff_datetime\"),\n",
    "                        \"PULocationID\",\n",
    "                        \"DOLocationID\",\n",
    "                        \"SR_Flag\")\n",
    "fhv_201801.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhv_tripdata_2015-01.csv  fhv_tripdata_2015-02.csv\r\n"
     ]
    }
   ],
   "source": [
    "#export new csv file\n",
    "#fhv_201501.write.save(path='data/t2/fhv/fhv_tripdata_2015-01.csv', format='csv', mode='append', sep=',', header=True)\n",
    "\n",
    "fhv_201501.write.csv('data/t2/fhv/fhv_tripdata_2015-02.csv')\n",
    "\n",
    "\n",
    "#print ('list of fhv tripdata files:')\n",
    "!ls data/t2/fhv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Green files\n",
    "\n",
    "For green there are 76 files:\n",
    "\n",
    "In 2015 - 1 :\n",
    "\n",
    "   1 diff on a total of 21 col: ['improvement_surcharge']\n",
    "           1/1 col add\n",
    "\n",
    "In 2016 - 7 :\n",
    "\n",
    "   2 diff on a total of 19 col: ['pulocationid', 'dolocationid']\n",
    "           2/2 col remove\n",
    "\n",
    "In 2019 - 1 :\n",
    "\n",
    "   1 diff on a total of 20 col: ['congestion_surcharge']\n",
    "           1/1 col add\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of yellow tripdata files:\n",
      "data/sampled/green_tripdata_2013-08.csv\r\n",
      "data/sampled/green_tripdata_2013-09.csv\r\n",
      "data/sampled/green_tripdata_2013-10.csv\r\n",
      "data/sampled/green_tripdata_2013-11.csv\r\n",
      "data/sampled/green_tripdata_2013-12.csv\r\n",
      "data/sampled/green_tripdata_2014-01.csv\r\n",
      "data/sampled/green_tripdata_2014-02.csv\r\n",
      "data/sampled/green_tripdata_2014-03.csv\r\n",
      "data/sampled/green_tripdata_2014-04.csv\r\n",
      "data/sampled/green_tripdata_2014-05.csv\r\n",
      "data/sampled/green_tripdata_2014-06.csv\r\n",
      "data/sampled/green_tripdata_2014-07.csv\r\n",
      "data/sampled/green_tripdata_2014-08.csv\r\n",
      "data/sampled/green_tripdata_2014-09.csv\r\n",
      "data/sampled/green_tripdata_2014-10.csv\r\n",
      "data/sampled/green_tripdata_2014-11.csv\r\n",
      "data/sampled/green_tripdata_2014-12.csv\r\n",
      "data/sampled/green_tripdata_2015-01.csv\r\n",
      "data/sampled/green_tripdata_2015-02.csv\r\n",
      "data/sampled/green_tripdata_2015-03.csv\r\n",
      "data/sampled/green_tripdata_2015-04.csv\r\n",
      "data/sampled/green_tripdata_2015-05.csv\r\n",
      "data/sampled/green_tripdata_2015-06.csv\r\n",
      "data/sampled/green_tripdata_2015-07.csv\r\n",
      "data/sampled/green_tripdata_2015-08.csv\r\n",
      "data/sampled/green_tripdata_2015-09.csv\r\n",
      "data/sampled/green_tripdata_2015-10.csv\r\n",
      "data/sampled/green_tripdata_2015-11.csv\r\n",
      "data/sampled/green_tripdata_2015-12.csv\r\n",
      "data/sampled/green_tripdata_2016-01.csv\r\n",
      "data/sampled/green_tripdata_2016-02.csv\r\n",
      "data/sampled/green_tripdata_2016-03.csv\r\n",
      "data/sampled/green_tripdata_2016-04.csv\r\n",
      "data/sampled/green_tripdata_2016-05.csv\r\n",
      "data/sampled/green_tripdata_2016-06.csv\r\n",
      "data/sampled/green_tripdata_2016-07.csv\r\n",
      "data/sampled/green_tripdata_2016-08.csv\r\n",
      "data/sampled/green_tripdata_2016-09.csv\r\n",
      "data/sampled/green_tripdata_2016-10.csv\r\n",
      "data/sampled/green_tripdata_2016-11.csv\r\n",
      "data/sampled/green_tripdata_2016-12.csv\r\n",
      "data/sampled/green_tripdata_2017-01.csv\r\n",
      "data/sampled/green_tripdata_2017-02.csv\r\n",
      "data/sampled/green_tripdata_2017-03.csv\r\n",
      "data/sampled/green_tripdata_2017-04.csv\r\n",
      "data/sampled/green_tripdata_2017-05.csv\r\n",
      "data/sampled/green_tripdata_2017-06.csv\r\n",
      "data/sampled/green_tripdata_2017-07.csv\r\n",
      "data/sampled/green_tripdata_2017-08.csv\r\n",
      "data/sampled/green_tripdata_2017-09.csv\r\n",
      "data/sampled/green_tripdata_2017-10.csv\r\n",
      "data/sampled/green_tripdata_2017-11.csv\r\n",
      "data/sampled/green_tripdata_2017-12.csv\r\n",
      "data/sampled/green_tripdata_2018-01.csv\r\n",
      "data/sampled/green_tripdata_2018-02.csv\r\n",
      "data/sampled/green_tripdata_2018-03.csv\r\n",
      "data/sampled/green_tripdata_2018-04.csv\r\n",
      "data/sampled/green_tripdata_2018-05.csv\r\n",
      "data/sampled/green_tripdata_2018-06.csv\r\n",
      "data/sampled/green_tripdata_2018-07.csv\r\n",
      "data/sampled/green_tripdata_2018-08.csv\r\n",
      "data/sampled/green_tripdata_2018-09.csv\r\n",
      "data/sampled/green_tripdata_2018-10.csv\r\n",
      "data/sampled/green_tripdata_2018-11.csv\r\n",
      "data/sampled/green_tripdata_2018-12.csv\r\n",
      "data/sampled/green_tripdata_2019-01.csv\r\n",
      "data/sampled/green_tripdata_2019-02.csv\r\n",
      "data/sampled/green_tripdata_2019-03.csv\r\n",
      "data/sampled/green_tripdata_2019-04.csv\r\n",
      "data/sampled/green_tripdata_2019-05.csv\r\n",
      "data/sampled/green_tripdata_2019-06.csv\r\n",
      "data/sampled/green_tripdata_2020-01.csv\r\n",
      "data/sampled/green_tripdata_2020-02.csv\r\n",
      "data/sampled/green_tripdata_2020-04.csv\r\n",
      "data/sampled/green_tripdata_2020-05.csv\r\n",
      "data/sampled/green_tripdata_2020-06.csv\r\n"
     ]
    }
   ],
   "source": [
    "print ('list of yellow tripdata files:')\n",
    "!ls data/sampled/green*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- Lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- Store_and_fwd_flag: string (nullable = true)\n",
      " |-- RateCodeID: integer (nullable = true)\n",
      " |-- Pickup_longitude: double (nullable = true)\n",
      " |-- Pickup_latitude: double (nullable = true)\n",
      " |-- Dropoff_longitude: double (nullable = true)\n",
      " |-- Dropoff_latitude: double (nullable = true)\n",
      " |-- Passenger_count: integer (nullable = true)\n",
      " |-- Trip_distance: double (nullable = true)\n",
      " |-- Fare_amount: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- MTA_tax: double (nullable = true)\n",
      " |-- Tip_amount: double (nullable = true)\n",
      " |-- Tolls_amount: double (nullable = true)\n",
      " |-- Ehail_fee: string (nullable = true)\n",
      " |-- Total_amount: double (nullable = true)\n",
      " |-- Payment_type: integer (nullable = true)\n",
      " |-- Trip_type: integer (nullable = true)\n",
      "\n",
      "+--------+--------------------+---------------------+------------------+----------+------------------+------------------+------------------+-----------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+------------+------------+---------+\n",
      "|VendorID|lpep_pickup_datetime|Lpep_dropoff_datetime|Store_and_fwd_flag|RateCodeID|  Pickup_longitude|   Pickup_latitude| Dropoff_longitude| Dropoff_latitude|Passenger_count|Trip_distance|Fare_amount|Extra|MTA_tax|Tip_amount|Tolls_amount|Ehail_fee|Total_amount|Payment_type|Trip_type|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------------+------------------+------------------+-----------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+------------+------------+---------+\n",
      "|       2| 2014-12-19 18:56:47|  2014-12-19 19:16:21|                 N|         1|-73.87925720214844|40.740623474121094|-73.91719055175781|40.74149703979492|              2|         2.18|       13.5|  1.0|    0.5|       0.0|         0.0|     null|        15.0|           2|        1|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------------+------------------+------------------+-----------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+------------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- Lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- Store_and_fwd_flag: string (nullable = true)\n",
      " |-- RateCodeID: integer (nullable = true)\n",
      " |-- Pickup_longitude: double (nullable = true)\n",
      " |-- Pickup_latitude: double (nullable = true)\n",
      " |-- Dropoff_longitude: double (nullable = true)\n",
      " |-- Dropoff_latitude: double (nullable = true)\n",
      " |-- Passenger_count: integer (nullable = true)\n",
      " |-- Trip_distance: double (nullable = true)\n",
      " |-- Fare_amount: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- MTA_tax: double (nullable = true)\n",
      " |-- Tip_amount: double (nullable = true)\n",
      " |-- Tolls_amount: double (nullable = true)\n",
      " |-- Ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- Total_amount: double (nullable = true)\n",
      " |-- Payment_type: integer (nullable = true)\n",
      " |-- Trip_type: integer (nullable = true)\n",
      "\n",
      "+--------+--------------------+---------------------+------------------+----------+------------------+-----------------+------------------+----------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+\n",
      "|VendorID|lpep_pickup_datetime|Lpep_dropoff_datetime|Store_and_fwd_flag|RateCodeID|  Pickup_longitude|  Pickup_latitude| Dropoff_longitude|Dropoff_latitude|Passenger_count|Trip_distance|Fare_amount|Extra|MTA_tax|Tip_amount|Tolls_amount|Ehail_fee|improvement_surcharge|Total_amount|Payment_type|Trip_type|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------------+-----------------+------------------+----------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+\n",
      "|       2| 2015-01-21 20:07:58|  2015-01-21 20:19:47|                 N|         1|-73.95250701904297|40.81092071533203|-73.94770812988281|40.7846794128418|              1|         2.48|       11.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|        12.3|           1|        1|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------------+-----------------+------------------+----------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      "\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+\n",
      "|       2| 2016-07-24 18:50:57|  2016-07-24 18:56:09|                 N|         1|          95|         102|              1|         1.49|        6.5|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|         7.3|           2|        1|\n",
      "|       2| 2016-07-27 08:40:44|  2016-07-27 09:06:41|                 N|         1|         244|         236|              1|         4.34|       19.0|  0.0|    0.5|       4.0|         0.0|     null|                  0.3|        23.8|           1|        1|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read fhv files\n",
    "green1_DF = (spark.read\n",
    "           .option(\"sep\", \",\")\n",
    "           .option(\"header\", True)\n",
    "           .option(\"inferSchema\", True)\n",
    "            .csv('data/sampled/green_tripdata_2014-12.csv'))\n",
    "green1_DF.printSchema()\n",
    "green1_DF.show(1)\n",
    "green2_DF = (spark.read\n",
    "           .option(\"sep\", \",\")\n",
    "           .option(\"header\", True)\n",
    "           .option(\"inferSchema\", True)\n",
    "            .csv('data/sampled/green_tripdata_2015-01.csv'))\n",
    "green2_DF.printSchema()\n",
    "green2_DF.show(1)\n",
    "green3_DF = (spark.read\n",
    "           .option(\"sep\", \",\")\n",
    "           .option(\"header\", True)\n",
    "           .option(\"inferSchema\", True)\n",
    "            .csv('data/sampled/green_tripdata_2016-07.csv'))\n",
    "green3_DF.printSchema()\n",
    "green3_DF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2015-01-21 20:07:58|  2015-01-21 20:19:47|                 N|         1|              1|         2.48|       11.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|        12.3|           1|        1|                null|\n",
      "+--------+--------------------+---------------------+------------------+----------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##1.modifing schema as needed\n",
    "green_201412 = green1_DF.withColumn(\"congestion_surcharge\",lit('null'))\\\n",
    "                        .select(\n",
    "                            col(\"VendorID\").alias(\"VendorID\"),\n",
    "                            col(\"lpep_pickup_datetime\").alias(\"lpep_pickup_datetime\"),\n",
    "                            col(\"Lpep_dropoff_datetime\").alias(\"lpep_dropoff_datetime\"),\n",
    "                            col(\"Store_and_fwd_flag\").alias(\"store_and_fwd_flag\"),\n",
    "                            col(\"RateCodeID\").alias(\"RatecodeID\"),\n",
    "                            col(\"Passenger_count\").alias(\"passenger_count\"),\n",
    "                            col(\"Trip_distance\").alias(\"trip_distance\"),\n",
    "                            col(\"Fare_amount\").alias(\"fare_amount\"),\n",
    "                            col(\"Extra\").alias(\"extra\"),\n",
    "                            col(\"MTA_tax\").alias(\"mta_tax\"),\n",
    "                            col(\"Tip_amount\").alias(\"tip_amount\"),\n",
    "                            col(\"Tolls_amount\").alias(\"tolls_amount\"),\n",
    "                            col(\"Ehail_fee\").alias(\"ehail_fee\"),\n",
    "                            col(\"improvement_surcharge\").alias(\"improvement_surcharge\"),\n",
    "                            col(\"Total_amount\").alias(\"total_amount\"),\n",
    "                            col(\"Payment_type\").alias(\"payment_type\"),\n",
    "                            col(\"Trip_type\").alias(\"trip_type\"),\n",
    "                            \"congestion_surcharge\")\n",
    "#green_201412.show(1)\n",
    "#\n",
    "#2.modifing schema as needed (with pu/do location id)\n",
    "green_201501 = green2_DF.withColumn(\"congestion_surcharge\",lit('null'))\\\n",
    "                        .select(\n",
    "                            col(\"VendorID\").alias(\"VendorID\"),\n",
    "                            col(\"lpep_pickup_datetime\").alias(\"lpep_pickup_datetime\"),\n",
    "                            col(\"Lpep_dropoff_datetime\").alias(\"lpep_dropoff_datetime\"),\n",
    "                            col(\"Store_and_fwd_flag\").alias(\"store_and_fwd_flag\"),\n",
    "                            col(\"RateCodeID\").alias(\"RatecodeID\"),\n",
    "                            col(\"Passenger_count\").alias(\"passenger_count\"),\n",
    "                            col(\"Trip_distance\").alias(\"trip_distance\"),\n",
    "                            col(\"Fare_amount\").alias(\"fare_amount\"),\n",
    "                            col(\"Extra\").alias(\"extra\"),\n",
    "                            col(\"MTA_tax\").alias(\"mta_tax\"),\n",
    "                            col(\"Tip_amount\").alias(\"tip_amount\"),\n",
    "                            col(\"Tolls_amount\").alias(\"tolls_amount\"),\n",
    "                            col(\"Ehail_fee\").alias(\"ehail_fee\"),\n",
    "                            col(\"improvement_surcharge\").alias(\"improvement_surcharge\"),\n",
    "                            col(\"Total_amount\").alias(\"total_amount\"),\n",
    "                            col(\"Payment_type\").alias(\"payment_type\"),\n",
    "                            col(\"Trip_type\").alias(\"trip_type\"),\n",
    "                            \"congestion_surcharge\")\n",
    "\n",
    "green_201501.show(1)\n",
    "\n",
    "#3.modifing schema as needed\n",
    "green_201707 = green3_DF.withColumn(\"congestion_surcharge\",lit('null'))\\\n",
    "#green_201707.show(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for geo location\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this subdf into a GeoDF, adding a \"geometry\" column to pinpoint the pickup location\n",
    "geometry = [Point(xy) for xy in zip(subdf['pickup_longitude'], subdf['pickup_latitude'])]\n",
    "geo_subdf = gpd.GeoDataFrame(subdf, geometry=geometry)\n",
    "geo_subdf\n",
    "# A geopanda dataframe has the possibility to create an R-tree index on it's geometry\n",
    "rtree = zones.sindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140, 236, 42]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By means of the intersection() method we can query for all the entries in the zones dataframe that \n",
    "# *can* intersect with a query point\n",
    "# Note: this mentod can return false positives; the actual zone is part of the result.\n",
    "# The method returns a generator. We use the list(.) constructor to convert this to a list.\n",
    "\n",
    "query_point = Point( df1.iloc[0].pickup_longitude, df1.iloc[0].pickup_latitude)\n",
    "possible_matches = list(rtree.intersection( query_point.bounds ))\n",
    "possible_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>141</td>\n",
       "      <td>0.041514</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>Lenox Hill West</td>\n",
       "      <td>141</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.96178 40.75988, -73.96197 40.759...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>237</td>\n",
       "      <td>0.042213</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>Upper East Side South</td>\n",
       "      <td>237</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.96613 40.76218, -73.96658 40.761...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>0.099739</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>Central Park</td>\n",
       "      <td>43</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.97255 40.76490, -73.97301 40.764...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                   zone  LocationID  \\\n",
       "140       141    0.041514    0.000077        Lenox Hill West         141   \n",
       "236       237    0.042213    0.000096  Upper East Side South         237   \n",
       "42         43    0.099739    0.000380           Central Park          43   \n",
       "\n",
       "       borough                                           geometry  \n",
       "140  Manhattan  POLYGON ((-73.96178 40.75988, -73.96197 40.759...  \n",
       "236  Manhattan  POLYGON ((-73.96613 40.76218, -73.96658 40.761...  \n",
       "42   Manhattan  POLYGON ((-73.97255 40.76490, -73.97301 40.764...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones.iloc[ possible_matches ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow files\n",
    "\n",
    "For yellow there are 131 files:\n",
    "\n",
    " In 2010 - 1 :\n",
    " \n",
    "   12 diff on a total of 18 col: ['vendor_id', 'pickup_datetime', 'dropoff_datetime', 'pickup_longitude', 'pickup_latitude', 'store_and_fwd_flag', 'dropoff_longitude', 'dropoff_latitude', 'fare_amount', 'tip_amount', 'tolls_amount', 'total_amount']\n",
    "         12/12 column name have changed:\n",
    "         \n",
    " In 2015 - 1 :\n",
    " \n",
    "   6 diff on a total of 19 col: ['vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'ratecodeid', 'extra', 'improvement_surcharge']\n",
    "         1/6 col add\n",
    "         5/6 name change\n",
    "         \n",
    " In 2016 - 7 :\n",
    " \n",
    "   2 diff on a total of 17 col: ['pulocationid', 'dolocationid']\n",
    "         2/2 col remove\n",
    "         \n",
    " In 2019 - 1 :\n",
    " \n",
    "   1 diff on a total of 18 col: ['congestion_surcharge']\n",
    "         1/1 col add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of fhv tripdata files:\n",
      "data/sampled/green_tripdata_2013-08.csv\r\n",
      "data/sampled/green_tripdata_2013-09.csv\r\n",
      "data/sampled/green_tripdata_2013-10.csv\r\n",
      "data/sampled/green_tripdata_2013-11.csv\r\n",
      "data/sampled/green_tripdata_2013-12.csv\r\n",
      "data/sampled/green_tripdata_2014-01.csv\r\n",
      "data/sampled/green_tripdata_2014-02.csv\r\n",
      "data/sampled/green_tripdata_2014-03.csv\r\n",
      "data/sampled/green_tripdata_2014-04.csv\r\n",
      "data/sampled/green_tripdata_2014-05.csv\r\n",
      "data/sampled/green_tripdata_2014-06.csv\r\n",
      "data/sampled/green_tripdata_2014-07.csv\r\n",
      "data/sampled/green_tripdata_2014-08.csv\r\n",
      "data/sampled/green_tripdata_2014-09.csv\r\n",
      "data/sampled/green_tripdata_2014-10.csv\r\n",
      "data/sampled/green_tripdata_2014-11.csv\r\n",
      "data/sampled/green_tripdata_2014-12.csv\r\n",
      "data/sampled/green_tripdata_2015-01.csv\r\n",
      "data/sampled/green_tripdata_2015-02.csv\r\n",
      "data/sampled/green_tripdata_2015-03.csv\r\n",
      "data/sampled/green_tripdata_2015-04.csv\r\n",
      "data/sampled/green_tripdata_2015-05.csv\r\n",
      "data/sampled/green_tripdata_2015-06.csv\r\n",
      "data/sampled/green_tripdata_2015-07.csv\r\n",
      "data/sampled/green_tripdata_2015-08.csv\r\n",
      "data/sampled/green_tripdata_2015-09.csv\r\n",
      "data/sampled/green_tripdata_2015-10.csv\r\n",
      "data/sampled/green_tripdata_2015-11.csv\r\n",
      "data/sampled/green_tripdata_2015-12.csv\r\n",
      "data/sampled/green_tripdata_2016-01.csv\r\n",
      "data/sampled/green_tripdata_2016-02.csv\r\n",
      "data/sampled/green_tripdata_2016-03.csv\r\n",
      "data/sampled/green_tripdata_2016-04.csv\r\n",
      "data/sampled/green_tripdata_2016-05.csv\r\n",
      "data/sampled/green_tripdata_2016-06.csv\r\n",
      "data/sampled/green_tripdata_2016-07.csv\r\n",
      "data/sampled/green_tripdata_2016-08.csv\r\n",
      "data/sampled/green_tripdata_2016-09.csv\r\n",
      "data/sampled/green_tripdata_2016-10.csv\r\n",
      "data/sampled/green_tripdata_2016-11.csv\r\n",
      "data/sampled/green_tripdata_2016-12.csv\r\n",
      "data/sampled/green_tripdata_2017-01.csv\r\n",
      "data/sampled/green_tripdata_2017-02.csv\r\n",
      "data/sampled/green_tripdata_2017-03.csv\r\n",
      "data/sampled/green_tripdata_2017-04.csv\r\n",
      "data/sampled/green_tripdata_2017-05.csv\r\n",
      "data/sampled/green_tripdata_2017-06.csv\r\n",
      "data/sampled/green_tripdata_2017-07.csv\r\n",
      "data/sampled/green_tripdata_2017-08.csv\r\n",
      "data/sampled/green_tripdata_2017-09.csv\r\n",
      "data/sampled/green_tripdata_2017-10.csv\r\n",
      "data/sampled/green_tripdata_2017-11.csv\r\n",
      "data/sampled/green_tripdata_2017-12.csv\r\n",
      "data/sampled/green_tripdata_2018-01.csv\r\n",
      "data/sampled/green_tripdata_2018-02.csv\r\n",
      "data/sampled/green_tripdata_2018-03.csv\r\n",
      "data/sampled/green_tripdata_2018-04.csv\r\n",
      "data/sampled/green_tripdata_2018-05.csv\r\n",
      "data/sampled/green_tripdata_2018-06.csv\r\n",
      "data/sampled/green_tripdata_2018-07.csv\r\n",
      "data/sampled/green_tripdata_2018-08.csv\r\n",
      "data/sampled/green_tripdata_2018-09.csv\r\n",
      "data/sampled/green_tripdata_2018-10.csv\r\n",
      "data/sampled/green_tripdata_2018-11.csv\r\n",
      "data/sampled/green_tripdata_2018-12.csv\r\n",
      "data/sampled/green_tripdata_2019-01.csv\r\n",
      "data/sampled/green_tripdata_2019-02.csv\r\n",
      "data/sampled/green_tripdata_2019-03.csv\r\n",
      "data/sampled/green_tripdata_2019-04.csv\r\n",
      "data/sampled/green_tripdata_2019-05.csv\r\n",
      "data/sampled/green_tripdata_2019-06.csv\r\n",
      "data/sampled/green_tripdata_2020-01.csv\r\n",
      "data/sampled/green_tripdata_2020-02.csv\r\n",
      "data/sampled/green_tripdata_2020-04.csv\r\n",
      "data/sampled/green_tripdata_2020-05.csv\r\n",
      "data/sampled/green_tripdata_2020-06.csv\r\n"
     ]
    }
   ],
   "source": [
    "print ('list of yellow tripdata files:')\n",
    "!ls data/sampled/yellow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
