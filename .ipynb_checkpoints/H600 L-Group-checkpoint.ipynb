{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Project H600 / L-Group\n",
    "***\n",
    "## Real world Data Exploration, Integration, Cleasning, Transformation and Analysis\n",
    "\n",
    "Data:\n",
    "The New York City Taxi and Limousine Commission (or TLC for short) has been publishing\n",
    "records about taxi trips in New York since 2009. \n",
    "\n",
    "The TLC trip dataset actually consists of 4 sub-datasets:\n",
    "\n",
    "    1.Yellow taxi records are records that record trip information of New York's famous yellow taxi cars\n",
    "\n",
    "    2.Green taxi records are records that record trip information by so-called 'boro' taxis, a newer service introduced in August of 2013 to improve taxi service and availability in the boroughs. \n",
    "\n",
    "    3.FHV records (short for 'For Hire Vehicles') record information from services that offered for-hire vehicles (such as Uber, Lyft, Via, and Juno), but also luxury limousine bases.\n",
    "\n",
    "    4.High volume FHV (FHVHV for short) are FHV records offered by services that make more than 10,000 trips per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=3g  pyspark-shell\"\n",
    "from pyspark.sql import SparkSession\n",
    "try: \n",
    "    spark\n",
    "    print(\"Spark application already started. Terminating existing application and starting new one\")\n",
    "    spark.stop()\n",
    "except: \n",
    "    pass\n",
    "# Create a new spark session (note, the * indicates to use all available CPU cores)\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"H600 L-Group\") \\\n",
    "    .getOrCreate()\n",
    "#When dealing with RDDs, we work the sparkContext object. See https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext\n",
    "sc=spark.sparkContext\n",
    "#in local mode, you will be able to access the Spark GUI at http://localhost:4040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Files & Data Exploration \n",
    "### 1.1 Count of files per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of green tripdata files:\n",
      "76\n",
      "count of yellow tripdata files:\n",
      "131\n",
      "count of fhv tripdata files:\n",
      "64\n",
      "count of fhvhv tripdata files:\n",
      "10\n",
      "count of all tripdata files:\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "print ('count of green tripdata files:')\n",
    "!find /home/bigdata/Desktop/Project/Data/green_tripdata_*.csv -type f | wc -l \n",
    "print ('count of yellow tripdata files:')\n",
    "!find /home/bigdata/Desktop/Project/Data/yellow_tripdata_*.csv -type f | wc -l\n",
    "print ('count of fhv tripdata files:')\n",
    "!find /home/bigdata/Desktop/Project/Data/fhv_tripdata_*.csv -type f | wc -l \n",
    "print ('count of fhvhv tripdata files:')\n",
    "!find /home/bigdata/Desktop/Project/Data/fhvhv_tripdata_*.csv -type f | wc -l\n",
    "print ('count of all tripdata files:')\n",
    "!find /home/bigdata/Desktop/Project/Data/*.csv -type f | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Files size and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating folders\n",
    "!mkdir -p exe01\n",
    "\n",
    "##creating size files for data exploration\n",
    "!mkdir -p exe01\n",
    "!wc Data/green_tripdata_*.csv > exe01/size_greentripdata.txt\n",
    "!wc Data/yellow_tripdata_*.csv > exe01/size_yellowtripdata.txt\n",
    "!wc Data/fhv_tripdata_*.csv > exe01/size_fhvtripdata.txt\n",
    "!wc Data/fhvhv_tripdata_*.csv > exe01/size_fhvhvtripdata.txt\n",
    "!wc Data/*.csv > exe01/size_alltripdata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Data/green_tripdata_2013-08.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-4c6ba6370c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msizegreen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exe01/size_greentripdata.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#sizegreen=pd.read_csv(\"exe01/size/size_greentripdata.txt\", header=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Data/green_tripdata_2013-08.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sizegreen=np.loadtxt(\"exe01/size_greentripdata.txt\")\n",
    "\n",
    "#sizegreen=pd.read_csv(\"exe01/size/size_greentripdata.txt\", header=None)\n",
    "#sizegreen.head()\n",
    "\n",
    "#plt.bar(\"File\", \"Count\", data = filecountmerged, color = \"blue\")\n",
    "#plt.xlabel(\"File type\")\n",
    "#plt.ylabel(\"Number\")\n",
    "#plt.title(\"Number of files per type\")\n",
    "#plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Yellow Trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16       46     2512 Data/green_tripdata_2013-08.csv\r\n",
      "      99      295    15235 Data/green_tripdata_2013-09.csv\r\n",
      "     339     1015    52330 Data/green_tripdata_2013-10.csv\r\n",
      "     757     2269   116683 Data/green_tripdata_2013-11.csv\r\n",
      "    1190     3568   183869 Data/green_tripdata_2013-12.csv\r\n",
      "    1587     4759   244988 Data/green_tripdata_2014-01.csv\r\n",
      "    1988     5962   307739 Data/green_tripdata_2014-02.csv\r\n",
      "    2569     7705   399204 Data/green_tripdata_2014-03.csv\r\n",
      "    2597     7789   403797 Data/green_tripdata_2014-04.csv\r\n",
      "    2823     8467   439546 Data/green_tripdata_2014-05.csv\r\n",
      "    2656     7966   413919 Data/green_tripdata_2014-06.csv\r\n",
      "    2529     7585   393897 Data/green_tripdata_2014-07.csv\r\n",
      "    2671     8011   416087 Data/green_tripdata_2014-08.csv\r\n",
      "    2703     8107   421297 Data/green_tripdata_2014-09.csv\r\n",
      "    2960     8878   460789 Data/green_tripdata_2014-10.csv\r\n",
      "    3071     9211   478112 Data/green_tripdata_2014-11.csv\r\n",
      "    3263     9787   507737 Data/green_tripdata_2014-12.csv\r\n",
      "    2993     8977   480094 Data/green_tripdata_2015-01.csv\r\n",
      "    3125     9373   502259 Data/green_tripdata_2015-02.csv\r\n",
      "    3419    10255   550108 Data/green_tripdata_2015-03.csv\r\n",
      "    3302     9904   530735 Data/green_tripdata_2015-04.csv\r\n",
      "    3547    10639   570765 Data/green_tripdata_2015-05.csv\r\n",
      "    3251     9751   523155 Data/green_tripdata_2015-06.csv\r\n",
      "    3059     9175   486263 Data/green_tripdata_2015-07.csv\r\n",
      "    3040     9118   483409 Data/green_tripdata_2015-08.csv\r\n",
      "    2969     8905   472094 Data/green_tripdata_2015-09.csv\r\n",
      "    3235     9703   514535 Data/green_tripdata_2015-10.csv\r\n",
      "    3038     9112   483101 Data/green_tripdata_2015-11.csv\r\n",
      "    3191     9571   507171 Data/green_tripdata_2015-12.csv\r\n",
      "    2871     8611   455677 Data/green_tripdata_2016-01.csv\r\n",
      "    2998     8992   475724 Data/green_tripdata_2016-02.csv\r\n",
      "    3129     9385   497243 Data/green_tripdata_2016-03.csv\r\n",
      "    3064     9190   487026 Data/green_tripdata_2016-04.csv\r\n",
      "    3050     9148   485196 Data/green_tripdata_2016-05.csv\r\n",
      "    2791     8371   443866 Data/green_tripdata_2016-06.csv\r\n",
      "    2654     7960   241078 Data/green_tripdata_2016-07.csv\r\n",
      "    2484     7450   225451 Data/green_tripdata_2016-08.csv\r\n",
      "    2313     6937   210116 Data/green_tripdata_2016-09.csv\r\n",
      "    2492     7474   226205 Data/green_tripdata_2016-10.csv\r\n",
      "    2286     6856   206990 Data/green_tripdata_2016-11.csv\r\n",
      "    2439     7315   221088 Data/green_tripdata_2016-12.csv\r\n",
      "    2133     6397   189231 Data/green_tripdata_2017-01.csv\r\n",
      "    2036     6106   180282 Data/green_tripdata_2017-02.csv\r\n",
      "    2304     6910   204167 Data/green_tripdata_2017-03.csv\r\n",
      "    2155     6463   191158 Data/green_tripdata_2017-04.csv\r\n",
      "    2111     6331   187007 Data/green_tripdata_2017-05.csv\r\n",
      "    1944     5830   172390 Data/green_tripdata_2017-06.csv\r\n",
      "    1821     5461   161559 Data/green_tripdata_2017-07.csv\r\n",
      "    1727     5179   153065 Data/green_tripdata_2017-08.csv\r\n",
      "    1756     5266   155802 Data/green_tripdata_2017-09.csv\r\n",
      "    1843     5527   163516 Data/green_tripdata_2017-10.csv\r\n",
      "    1740     5218   154256 Data/green_tripdata_2017-11.csv\r\n",
      "    1804     5410   159695 Data/green_tripdata_2017-12.csv\r\n",
      "    1583     4747   140085 Data/green_tripdata_2018-01.csv\r\n",
      "    1536     4606   136037 Data/green_tripdata_2018-02.csv\r\n",
      "    1667     4999   147577 Data/green_tripdata_2018-03.csv\r\n",
      "    1595     4783   141434 Data/green_tripdata_2018-04.csv\r\n",
      "    1589     4765   140699 Data/green_tripdata_2018-05.csv\r\n",
      "    1477     4429   131129 Data/green_tripdata_2018-06.csv\r\n",
      "    1369     4105   121383 Data/green_tripdata_2018-07.csv\r\n",
      "    1331     3991   117958 Data/green_tripdata_2018-08.csv\r\n",
      "    1332     3994   118055 Data/green_tripdata_2018-09.csv\r\n",
      "    1420     4258   125763 Data/green_tripdata_2018-10.csv\r\n",
      "    1312     3934   116468 Data/green_tripdata_2018-11.csv\r\n",
      "    1371     4111   121532 Data/green_tripdata_2018-12.csv\r\n",
      "    1259     3775   112967 Data/green_tripdata_2019-01.csv\r\n",
      "    1147     3439   104284 Data/green_tripdata_2019-02.csv\r\n",
      "    1197     3589   108842 Data/green_tripdata_2019-03.csv\r\n",
      "    1024     3070    93303 Data/green_tripdata_2019-04.csv\r\n",
      "    1005     3013    91727 Data/green_tripdata_2019-05.csv\r\n",
      "     936     2806    85508 Data/green_tripdata_2019-06.csv\r\n",
      "     896     2686    80652 Data/green_tripdata_2020-01.csv\r\n",
      "     798     2392    72193 Data/green_tripdata_2020-02.csv\r\n",
      "      72      214     6575 Data/green_tripdata_2020-04.csv\r\n",
      "     115      343    10356 Data/green_tripdata_2020-05.csv\r\n",
      "     127      379    11489 Data/green_tripdata_2020-06.csv\r\n",
      "  154090   462118 19945234 total\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the contents of a file into an RDD. Note - when run on the cluster this load from HDFS (inside /user/$USER/)\n",
    "# if you really want to load from HDFS, you can also put the full HDFS url, e.g.\n",
    "# hdfs://public00:8020/user/<your_user_id_here>/data/books/pg20417.txt\n",
    "fileName = 'Data/green_tripdata_2020-01.csv'\n",
    "TaxiRDD = sc.textFile(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge',\n",
       " ',2020-01-27 06:40:00,2020-01-27 07:25:00,,,159,61,,19.84,40.95,2.75,0,0,6.12,,0.3,50.12,,,',\n",
       " '2,2020-01-18 01:01:42,2020-01-18 01:04:57,N,1,7,146,1,.56,4.5,0.5,0.5,1.45,0,,0.3,7.25,1,1,0',\n",
       " '2,2020-01-15 13:52:01,2020-01-15 14:13:09,N,1,134,77,1,5.87,22,0,0.5,0,0,,0.3,22.8,1,1,0',\n",
       " '2,2020-01-30 23:49:37,2020-01-31 00:12:17,N,1,42,143,1,5.40,20,0.5,0.5,4.81,0,,0.3,28.86,1,1,2.75']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaxiRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge'],\n",
       " [',2020-01-27',\n",
       "  '06:40:00,2020-01-27',\n",
       "  '07:25:00,,,159,61,,19.84,40.95,2.75,0,0,6.12,,0.3,50.12,,,'],\n",
       " ['2,2020-01-18',\n",
       "  '01:01:42,2020-01-18',\n",
       "  '01:04:57,N,1,7,146,1,.56,4.5,0.5,0.5,1.45,0,,0.3,7.25,1,1,0']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tupleRDD = TaxiRDD.map(lambda line: line.split())\n",
    "tupleRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge',\n",
       " ',2020-01-27',\n",
       " '06:40:00,2020-01-27',\n",
       " '07:25:00,,,159,61,,19.84,40.95,2.75,0,0,6.12,,0.3,50.12,,,',\n",
       " '2,2020-01-18']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD = TaxiRDD.flatMap(lambda line: line.split())\n",
    "wordsRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2686"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2686"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD.map(lambda x: 1).reduce(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a word count on all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTaxiRDD = sc.textFile('Data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5036382"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTaxiRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5036382"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTaxiRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow taxi records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
