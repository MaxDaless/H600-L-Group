{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampled Dataset exploration, meta-data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: this notebook assumes that:\n",
    "\n",
    "- The data are in \"MY_PARENT_FOLDER/data/sampled/\" folder. You can run the bash script \"download_metadata.sh\" to download data and metadata in the correct folders to execute the jupyter notebooks.\n",
    "- The data are sampled to be run on a personnal computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports go here\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute basic statistics about the number of files in this sub-dataset, their size, and the number of records (lines) in each file. For length and number of records, give the min, max, mean, 25, 50, 75, 90 percentiles values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of green tripdata files:\n",
      "76\n",
      "count of yellow tripdata files:\n",
      "131\n",
      "count of fhv tripdata files:\n",
      "64\n",
      "count of fhvhv tripdata files:\n",
      "10\n",
      "count of all tripdata files:\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "print ('count of green tripdata files:')\n",
    "!find data/sampled/green_tripdata_*.csv -type f | wc -l \n",
    "print ('count of yellow tripdata files:')\n",
    "!find data/sampled/yellow_tripdata_*.csv -type f | wc -l\n",
    "print ('count of fhv tripdata files:')\n",
    "!find data/sampled/fhv_tripdata_*.csv -type f | wc -l \n",
    "print ('count of fhvhv tripdata files:')\n",
    "!find data/sampled/fhvhv_tripdata_*.csv -type f | wc -l\n",
    "print ('count of all tripdata files:')\n",
    "!find data/sampled/*.csv -type f | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files stats in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file type called yellow there are 131 files.\n",
      "     Here are some metrics based on their size in bytes:\n",
      "       -min value           :  43103\n",
      "       -max value           :  5959352\n",
      "       -mean value          :  3750759.69\n",
      "       -25 percentile value :  1756967.0\n",
      "       -50 percentile value :  4442047.0\n",
      "       -75 percentile value :  5123591.5\n",
      "       -90 percentile value :  5491438.0\n",
      "       -total file sum size :  491349519\n",
      "For the file type called green there are 76 files.\n",
      "     Here are some metrics based on their size in bytes:\n",
      "       -min value           :  2512\n",
      "       -max value           :  570765\n",
      "       -mean value          :  262437.29\n",
      "       -25 percentile value :  121494.75\n",
      "       -50 percentile value :  190194.5\n",
      "       -75 percentile value :  456955.0\n",
      "       -90 percentile value :  499751.0\n",
      "       -total file sum size :  19945234\n",
      "For the file type called fhv there are 74 files.\n",
      "     Here are some metrics based on their size in bytes:\n",
      "       -min value           :  52060\n",
      "       -max value           :  3339455\n",
      "       -mean value          :  1263540.66\n",
      "       -25 percentile value :  239082.25\n",
      "       -50 percentile value :  725289.0\n",
      "       -75 percentile value :  2545631.75\n",
      "       -90 percentile value :  3003289.6\n",
      "       -total file sum size :  93502009\n",
      "For the file type called fhvhv there are 10 files.\n",
      "     Here are some metrics based on their size in bytes:\n",
      "       -min value           :  535789\n",
      "       -max value           :  2978931\n",
      "       -mean value          :  2007750.7\n",
      "       -25 percentile value :  1121047.25\n",
      "       -50 percentile value :  2542280.0\n",
      "       -75 percentile value :  2687857.25\n",
      "       -90 percentile value :  2804332.8\n",
      "       -total file sum size :  20077507\n"
     ]
    }
   ],
   "source": [
    "list_taxi = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
    "#list_taxi = [\"green\"]\n",
    "for taxi_brand in list_taxi :\n",
    "    list_files = {}\n",
    "    list_files[taxi_brand] = []\n",
    "    nb_files = 0\n",
    "    size_b = []\n",
    "    # List the file from the same taxi company brand \n",
    "    for file in glob.glob(\"data/sampled/%s*.csv\" %(taxi_brand)):\n",
    "        nb_files = nb_files+1\n",
    "        #Save in list the file name\n",
    "        list_files[taxi_brand].append(file)\n",
    "        size_b.append(os.path.getsize(file))\n",
    "    print(\"For the file type called %s there are %i files.\" %(taxi_brand, nb_files))\n",
    "    # Get size basic stats\n",
    "    print(\"     Here are some metrics based on their size in bytes:\")\n",
    "    print(\"       -min value           : \", np.min(size_b))\n",
    "    print(\"       -max value           : \", np.max(size_b))\n",
    "    print(\"       -mean value          : \", np.round(np.mean(size_b),2))\n",
    "    print(\"       -25 percentile value : \", np.quantile(size_b, .25)) \n",
    "    print(\"       -50 percentile value : \", np.quantile(size_b, .50)) \n",
    "    print(\"       -75 percentile value : \", np.quantile(size_b, .75)) \n",
    "    print(\"       -90 percentile value : \", np.quantile(size_b, .90))\n",
    "    print(\"       -total file sum size : \", np.sum(size_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files stats in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the taxi brand called yellow there are still 10 files.\n",
      "     Here are some metrics based on their size in rows count:\n",
      "       -min value           :  477\n",
      "       -max value           :  32301\n",
      "       -mean value          :  24204.51\n",
      "       -25 percentile value :  19990.0\n",
      "       -50 percentile value :  26295.0\n",
      "       -75 percentile value :  29081.0\n",
      "       -90 percentile value :  30203.0\n",
      "       -total row number    :  3170791\n",
      "For the taxi brand called green there are still 10 files.\n",
      "     Here are some metrics based on their size in rows count:\n",
      "       -min value           :  16\n",
      "       -max value           :  3547\n",
      "       -mean value          :  2027.5\n",
      "       -25 percentile value :  1359.75\n",
      "       -50 percentile value :  2073.5\n",
      "       -75 percentile value :  2893.25\n",
      "       -90 percentile value :  3127.0\n",
      "       -total row number    :  154090\n",
      "For the taxi brand called fhv there are still 10 files.\n",
      "     Here are some metrics based on their size in rows count:\n",
      "       -min value           :  960\n",
      "       -max value           :  47704\n",
      "       -mean value          :  23128.39\n",
      "       -25 percentile value :  7975.25\n",
      "       -50 percentile value :  22391.5\n",
      "       -75 percentile value :  39336.5\n",
      "       -90 percentile value :  44120.3\n",
      "       -total row number    :  1711501\n",
      "For the taxi brand called fhvhv there are still 10 files.\n",
      "     Here are some metrics based on their size in rows count:\n",
      "       -min value           :  8626\n",
      "       -max value           :  47704\n",
      "       -mean value          :  32182.9\n",
      "       -25 percentile value :  18023.0\n",
      "       -50 percentile value :  40715.0\n",
      "       -75 percentile value :  43057.25\n",
      "       -90 percentile value :  44923.0\n",
      "       -total row number    :  321829\n"
     ]
    }
   ],
   "source": [
    "for taxi_brand in list_taxi :\n",
    "    names={}\n",
    "    size_r=[]\n",
    "    for fn in glob.glob(\"data/sampled/%s*.csv\" %(taxi_brand)):\n",
    "        with open(fn) as f:\n",
    "            names[fn]=sum(1 for line in f if line.strip())      \n",
    "        # Save in list files sizes in rows\n",
    "        size_r=list(names.values())\n",
    "    print(\"For the taxi brand called %s there are still %i files.\" %(taxi_brand, nb_files))\n",
    "    # Get size basic stat\n",
    "    print(\"     Here are some metrics based on their size in rows count:\")\n",
    "    print(\"       -min value           : \", np.min(size_r))\n",
    "    print(\"       -max value           : \", np.max(size_r))\n",
    "    print(\"       -mean value          : \", np.round(np.mean(size_r),2))\n",
    "    print(\"       -25 percentile value : \", np.quantile(size_r, .25)) \n",
    "    print(\"       -50 percentile value : \", np.quantile(size_r, .50)) \n",
    "    print(\"       -75 percentile value : \", np.quantile(size_r, .75)) \n",
    "    print(\"       -90 percentile value : \", np.quantile(size_r, .90))\n",
    "    print(\"       -total row number    : \", np.sum(size_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the schema evolution.\n",
    "\n",
    "Over time, the relational schema associated to each type of trip data (yellow, green, fhv, hvfhv) has changed. Let us analyze the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- For yellow there are 131 files.\n",
      "     In 2010 - 1 :\n",
      "         12 diff on a total of 18 col: ['vendor_id', 'pickup_datetime', 'dropoff_datetime', 'pickup_longitude', 'pickup_latitude', 'store_and_fwd_flag', 'dropoff_longitude', 'dropoff_latitude', 'fare_amount', 'tip_amount', 'tolls_amount', 'total_amount']\n",
      "             12/12 column name have changed:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 154: expected 18 fields, saw 19\\nSkipping line 2380: expected 18 fields, saw 19\\nSkipping line 8408: expected 18 fields, saw 19\\nSkipping line 11210: expected 18 fields, saw 19\\nSkipping line 11353: expected 18 fields, saw 19\\nSkipping line 11663: expected 18 fields, saw 19\\nSkipping line 13047: expected 18 fields, saw 19\\nSkipping line 13900: expected 18 fields, saw 19\\nSkipping line 14577: expected 18 fields, saw 19\\nSkipping line 15041: expected 18 fields, saw 19\\nSkipping line 15844: expected 18 fields, saw 19\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     In 2015 - 1 :\n",
      "         6 diff on a total of 19 col: ['vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'ratecodeid', 'extra', 'improvement_surcharge']\n",
      "             1/6 col add\n",
      "             5/6 name change\n",
      "     In 2016 - 7 :\n",
      "         2 diff on a total of 17 col: ['pulocationid', 'dolocationid']\n",
      "             2/2 col remove\n",
      "     In 2019 - 1 :\n",
      "         1 diff on a total of 18 col: ['congestion_surcharge']\n",
      "             1/1 col add\n",
      "- For green there are 76 files.\n",
      "     In 2015 - 1 :\n",
      "         1 diff on a total of 21 col: ['improvement_surcharge']\n",
      "             1/1 col add\n",
      "     In 2016 - 7 :\n",
      "         2 diff on a total of 19 col: ['pulocationid', 'dolocationid']\n",
      "             2/2 col remove\n",
      "     In 2019 - 1 :\n",
      "         1 diff on a total of 20 col: ['congestion_surcharge']\n",
      "             1/1 col add\n",
      "- For fhv there are 64 files.\n",
      "     In 2017 - 1 :\n",
      "         4 diff on a total of 5 col: ['pickup_datetime', 'dropoff_datetime', 'pulocationid', 'dolocationid']\n",
      "             2/4 col add\n",
      "             2/4 name change\n",
      "     In 2017 - 7 :\n",
      "         1 diff on a total of 6 col: ['sr_flag']\n",
      "             1/1 col add\n",
      "     In 2018 - 1 :\n",
      "         1 diff on a total of 7 col: ['dispatching_base_number']\n",
      "             1/1 col add\n",
      "     In 2019 - 1 :\n",
      "         1 diff on a total of 6 col: ['dispatching_base_number']\n",
      "             1/1 col remove\n",
      "- For fhvhv there are 10 files.\n",
      "     There is no diff between files\n"
     ]
    }
   ],
   "source": [
    "# Code to help analyze the schema changes goes here\n",
    "list_taxi = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
    "#list_taxi = [\"green\"]\n",
    "for taxi_brand in list_taxi :\n",
    "    list_files = {}\n",
    "    list_files[taxi_brand] = []\n",
    "    nb_files = 0\n",
    "    size = []\n",
    "    count = 0\n",
    "     # List the file from the same taxi company brand \n",
    "    for file in glob.glob(\"data/sampled/%s_*.csv\" %(taxi_brand)):\n",
    "        nb_files = nb_files+1\n",
    "        # Save in list the file name\n",
    "        list_files[taxi_brand].append(file)\n",
    "        #size.append(os.path.getsize(file))\n",
    "    # Order the files list by file names\n",
    "    list_files[taxi_brand].sort()\n",
    "    print(\"- For %s there are %i files.\" %(taxi_brand, nb_files))\n",
    "    for yr in range(0,nb_files):\n",
    "        # Read file by file\n",
    "        df = pd.read_csv(list_files[taxi_brand][yr],error_bad_lines=False, sep=',')\n",
    "        # Extract the head of the file\n",
    "        head = list(df)\n",
    "        head_lower = [ x.lower() for x in head ]\n",
    "        # Remove the blank space in the col name\n",
    "        head_lower_clean = [x.strip(' ') for x in head_lower]\n",
    "        #print(yr,head_lower)\n",
    "        # counter for check file\n",
    "        count = count + 1\n",
    "        # Save first file schema as reference\n",
    "        if yr == 0 :\n",
    "            nb_col_ref = len(head)\n",
    "            col_name_ref = head_lower_clean\n",
    "            time_period = int(list_files[taxi_brand][yr][len(taxi_brand)+23:len(taxi_brand)+27])\n",
    "            # print(col_name_ref)\n",
    "        else :\n",
    "            # Compare reference schema with the shema of all the others files\n",
    "            if head_lower_clean != col_name_ref :\n",
    "                diff_name_col_add = [ x for x in head_lower_clean if x not in set(col_name_ref) ]\n",
    "                diff_name_col_rm = [ x for x in col_name_ref if x not in set (head_lower_clean) ]\n",
    "                #print(diff_name_col_add)\n",
    "                #print(diff_name_col_rm)\n",
    "                if len(diff_name_col_add) > 0 :\n",
    "                    diff_name_col = diff_name_col_add\n",
    "                elif len(diff_name_col_add) == 0 :\n",
    "                    diff_name_col = diff_name_col_rm\n",
    "                #pos_col_change = []\n",
    "                #for i in range(0,len(diff_name_col)) :\n",
    "                #    pos_col_change.append(head_lower_clean.index(diff_name_col[i]))\n",
    "                print(\"     In %i - %i :\" %(int(list_files[taxi_brand][yr][len(taxi_brand)+23:len(taxi_brand)+27]),int(list_files[taxi_brand][yr][len(taxi_brand)+28:len(taxi_brand)+30])))\n",
    "                print(\"         %i diff on a total of %i col:\" %(len(diff_name_col),len(head_lower_clean)), diff_name_col)\n",
    "                # Check if the order of the column have changed\n",
    "                #print(head_lower_clean)\n",
    "                 #print(col_name_ref)\n",
    "                #print(diff_name_col)\n",
    "                ## If the numbers of column change\n",
    "                if len(head_lower_clean) != nb_col_ref :\n",
    "                    # If the numbers of column is different from reference yr check what is the new column name\n",
    "                    diff_nb_col = len(head_lower_clean) - nb_col_ref\n",
    "                    # find the new/remove col name())\n",
    "                    #diff_name_col = [ x for x in head_lower_clean if x not in set(col_name_ref) ]\n",
    "                    # Check if the order of the column have changed\n",
    "                    #print(diff_name_col)\n",
    "                    #pos_col_change = []\n",
    "                    #for i in range(0,len(diff_name_col)) :\n",
    "                    #    pos_col_change.append(head_lower_clean.index(diff_name_col[i]))\n",
    "                    if diff_nb_col > 0 :\n",
    "                            print(\"             %i/%i col add\" %(diff_nb_col,len(diff_name_col)))\n",
    "                    elif diff_nb_col < 0 :\n",
    "                        print(\"             %i/%i col remove\" %(abs(diff_nb_col),len(diff_name_col)))\n",
    "                    if abs(diff_nb_col) != len(diff_name_col) :\n",
    "                        nb_name_diff = len(diff_name_col) - abs(diff_nb_col) \n",
    "                        print(\"             %i/%i name change\" %(nb_name_diff,len(diff_name_col)))\n",
    "                elif (sum(len(i) for i in head_lower_clean)) != (sum(len(i) for i in col_name_ref)) :\n",
    "                    nb_name_change = len(set(col_name_ref) - set(head_lower_clean))\n",
    "                    print(\"             %i/%i column name have changed:\" %(nb_name_change, len(diff_name_col)))\n",
    "                    new_name=set(col_name_ref) - set(head_lower_clean)\n",
    "                    old_name=set(head_lower_clean) - set(col_name_ref)\n",
    "                    #print(\"                 New name are:\",new_name)\n",
    "                    #print(old_name, col_name_ref)\n",
    "                col_name_ref = head_lower_clean\n",
    "                nb_col_ref = len(head_lower_clean)\n",
    "                count = count - 1\n",
    "    if count == nb_files:\n",
    "        print(\"     There is no diff between files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of schema changes for fhv cab data files\n",
    "\n",
    "Analyze the schema changes for the FHV cab data files. Write down your conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For fhv there are 64 files:\n",
    "\n",
    "     In 2017 - 1 :\n",
    "         4 diff on a total of 5 col: ['pickup_datetime', 'dropoff_datetime', 'pulocationid', 'dolocationid']\n",
    "             2/4 col add\n",
    "             2/4 name change\n",
    "     In 2017 - 7 :\n",
    "         1 diff on a total of 6 col: ['sr_flag']\n",
    "             1/1 col add\n",
    "     In 2018 - 1 :\n",
    "         1 diff on a total of 7 col: ['dispatching_base_number']\n",
    "             1/1 col add\n",
    "     In 2019 - 1 :\n",
    "         1 diff on a total of 6 col: ['dispatching_base_number']\n",
    "             1/1 col remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of schema changes for fhvhv data files\n",
    "\n",
    "Analyze the schema changes for the FHVHV cab data files. Write down your conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- For fhvhv there are 10 files.\n",
    "     There is no diff between files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of schema changes for green cab data files\n",
    "\n",
    "Analyze the schema changes for the green taxi data files. Write down your conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For green there are 76 files:\n",
    "\n",
    "     In 2015 - 1 :\n",
    "         1 diff on a total of 21 col: ['improvement_surcharge']\n",
    "             1/1 col add\n",
    "     In 2016 - 7 :\n",
    "         2 diff on a total of 19 col: ['pulocationid', 'dolocationid']\n",
    "             2/2 col remove\n",
    "     In 2019 - 1 :\n",
    "         1 diff on a total of 20 col: ['congestion_surcharge']\n",
    "             1/1 col add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of schema changes for yellow cab data files\n",
    "\n",
    "Analyze the schema changes for the Yellow taxi data files. Write down your conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For yellow there are 131 files:\n",
    " \n",
    "     In 2010 - 1 :\n",
    "         12 diff on a total of 18 col: ['vendor_id', 'pickup_datetime', 'dropoff_datetime', 'pickup_longitude', 'pickup_latitude', 'store_and_fwd_flag', 'dropoff_longitude', 'dropoff_latitude', 'fare_amount', 'tip_amount', 'tolls_amount', 'total_amount']\n",
    "             12/12 column name have changed:\n",
    "     In 2015 - 1 :\n",
    "         6 diff on a total of 19 col: ['vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'ratecodeid', 'extra', 'improvement_surcharge']\n",
    "             1/6 col add\n",
    "             5/6 name change\n",
    "     In 2016 - 7 :\n",
    "         2 diff on a total of 17 col: ['pulocationid', 'dolocationid']\n",
    "             2/2 col remove\n",
    "     In 2019 - 1 :\n",
    "         1 diff on a total of 18 col: ['congestion_surcharge']\n",
    "             1/1 col add"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
