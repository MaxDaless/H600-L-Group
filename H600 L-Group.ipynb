{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Project H600 / L-Group \n",
    "## Real world Data Exploration, Integration, Cleasning, Transformation and Analysis\n",
    "### Can be run on a personnal computer\n",
    "\n",
    " **Note: this notebook assumes that:**\n",
    "    - The sampled data is in \"MY_PARENT_FOLDER/data/sampled/\" folder.\n",
    "    - You can run the bash script \"download_metadata.sh\" to download data and metadata in the correct folders to execute the jupyter notebooks.\n",
    "\n",
    "Data:\n",
    "The New York City Taxi and Limousine Commission (or TLC for short) has been publishing\n",
    "records about taxi trips in New York since 2009. \n",
    "\n",
    "The TLC trip dataset actually consists of 4 sub-datasets:\n",
    "\n",
    "    1.Yellow taxi records are records that record trip information of New York's famous yellow taxi cars\n",
    "\n",
    "    2.Green taxi records are records that record trip information by so-called 'boro' taxis, a newer service introduced in August of 2013 to improve taxi service and availability in the boroughs. \n",
    "\n",
    "    3.FHV records (short for 'For Hire Vehicles') record information from services that offered for-hire vehicles (such as Uber, Lyft, Via, and Juno), but also luxury limousine bases.\n",
    "\n",
    "    4.High volume FHV (FHVHV for short) are FHV records offered by services that make more than 10,000 trips per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark application already started. Terminating existing application and starting new one\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=3g  pyspark-shell\"\n",
    "from pyspark.sql import SparkSession\n",
    "try: \n",
    "    spark\n",
    "    print(\"Spark application already started. Terminating existing application and starting new one\")\n",
    "    spark.stop()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "# Create a new spark session (note, the * indicates to use all available CPU cores)\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"H600 L-Group\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "#When dealing with RDDs, we work the sparkContext object. See https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext\n",
    "sc=spark.sparkContext\n",
    "\n",
    "#in local mode, you will be able to access the Spark GUI at http://localhost:4040\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ READY TO START -----------\r\n"
     ]
    }
   ],
   "source": [
    "# Check if the files and forlder are on the good folder to exectue the following code.\n",
    "!./check_files.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for the files shema\n",
    "The schema of the files have changes over time (name, order and numbers of column). The following script look for the kind of change and the date when it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19945234\n",
      "- For the taxi brand called green there are 76 files.\n",
      "     there is diff in 2015 - 1 :\n",
      "          1 col add: improvement_surcharge in position [17]\n",
      "     there is diff in 2016 - 7 :\n",
      "          2 col remove: pulocationid and dolocationid in position [5, 6]\n",
      "     there is diff in 2019 - 1 :\n",
      "          1 col add: congestion_surcharge in position [19]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Get the list of file\n",
    "taxi_brand=\"green\"\n",
    "list_files = {}\n",
    "list_files[taxi_brand] = []\n",
    "nb_files = 0\n",
    "size = []\n",
    "# List the file from the same taxi company brand \n",
    "for file in glob.glob(\"data/sampled/%s*.csv\" %(taxi_brand)):\n",
    "    nb_files = nb_files+1\n",
    "    # Save in list the file name\n",
    "    list_files[taxi_brand].append(file)\n",
    "    \"size.append(os.path.getsize(file))\n",
    "# Order the files list by file names\n",
    "print(np.sum(size))\n",
    "list_files[taxi_brand].sort()\n",
    "print(\"- For the taxi brand called %s there are %i files.\" %(taxi_brand, nb_files))\n",
    "for yr in range(0,nb_files):\n",
    "    # Read file by file\n",
    "    df = pd.read_csv(list_files[taxi_brand][yr],sep=',')\n",
    "    # Extract the head of the file\n",
    "    head = list(df)\n",
    "    # Save first file schema as reference\n",
    "    if yr == 0 :\n",
    "        nb_col_ref = len(head)\n",
    "        col_name_ref = [ x.lower() for x in head ]\n",
    "        # print(col_name_ref)\n",
    "    else :\n",
    "        # Compare reference schema with the shema of all the others files\n",
    "        if len(head) != nb_col_ref :\n",
    "            # If the numbers of column is different from reference yr check what is the new column name\n",
    "            print(\"     there is diff in %i - %i :\" %(int(list_files[taxi_brand][yr][28:32]),int(list_files[taxi_brand][yr][33:35])))\n",
    "            diff_nb_col = len(head) - nb_col_ref\n",
    "            ## print(len(head),nb_col_ref)\n",
    "            # lower case for all col names\n",
    "            head_lower_new = [ x.lower() for x in head ]\n",
    "            # find the new/remove col name\n",
    "            diff_name_col = [ x for x in head_lower_new if x not in col_name_ref ]\n",
    "            col_name_ref = head_lower_new\n",
    "            nb_col_ref = len(head_lower_new)\n",
    "            # Check if the order of the column have changed\n",
    "            pos_col_change = []\n",
    "            for i in range(0,len(diff_name_col)) :\n",
    "                pos_col_change.append(head_lower_new.index(diff_name_col[i]))\n",
    "            if diff_nb_col > 0 :\n",
    "                print(\"          %i col add: %s in position %s\" %(diff_nb_col, ' and '.join(diff_name_col), str(pos_col_change)))\n",
    "            else :\n",
    "                print(\"          %i col remove: %s in position %s\" %(abs(diff_nb_col), ' and '.join(diff_name_col), str(pos_col_change)))\n",
    "            \n",
    "        else :    \n",
    "    \n",
    "\n",
    "\n",
    "#Check the files\n",
    "    \n",
    "    # Check if the file name have all the same lenght to determine start and end date\n",
    "#    if nb_files == 1:\n",
    "#        len_filename_ref = len(file)\n",
    "#    if len(file) != len_filename_ref:\n",
    " #       print(\"The file %s in pos %i have longer file name of %i \" %(file, nb_files, (len(file)-len_filename_ref)))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#print(\"The file name pattern look likes %s\" %(file) )\n",
    "#yr_file=[]\n",
    "#mth_file=[]\n",
    "#for yr in range(0,nb_files):\n",
    "#    tmp1 = int(list_files[taxi_brand][yr][28:32])\n",
    "#    print(tmp1)\n",
    "#    int(list_files[taxi_brand][yr][33:35])\n",
    "#    df = pd.DataFrame({'year': int(list_files[taxi_brand][yr][28:32]),\n",
    "#                       'month': int(list_files[taxi_brand][yr][33:35])})\n",
    "#    pd.to_datetime(df[[\"year\",\"month\"]])\n",
    "\n",
    "#df = pd.DataFrame({'year'} : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the contents of a file into an RDD. Note - when run on the cluster this load from HDFS (inside /user/$USER/)\n",
    "# if you really want to load from HDFS, you can also put the full HDFS url, e.g.\n",
    "# hdfs://public00:8020/user/<your_user_id_here>/data/books/pg20417.txt\n",
    "fileName = 'Data/green_tripdata_2020-01.csv'\n",
    "TaxiRDD = sc.textFile(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge',\n",
       " ',2020-01-27 06:40:00,2020-01-27 07:25:00,,,159,61,,19.84,40.95,2.75,0,0,6.12,,0.3,50.12,,,',\n",
       " '2,2020-01-18 01:01:42,2020-01-18 01:04:57,N,1,7,146,1,.56,4.5,0.5,0.5,1.45,0,,0.3,7.25,1,1,0',\n",
       " '2,2020-01-15 13:52:01,2020-01-15 14:13:09,N,1,134,77,1,5.87,22,0,0.5,0,0,,0.3,22.8,1,1,0',\n",
       " '2,2020-01-30 23:49:37,2020-01-31 00:12:17,N,1,42,143,1,5.40,20,0.5,0.5,4.81,0,,0.3,28.86,1,1,2.75']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaxiRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge'],\n",
       " [',2020-01-27',\n",
       "  '06:40:00,2020-01-27',\n",
       "  '07:25:00,,,159,61,,19.84,40.95,2.75,0,0,6.12,,0.3,50.12,,,'],\n",
       " ['2,2020-01-18',\n",
       "  '01:01:42,2020-01-18',\n",
       "  '01:04:57,N,1,7,146,1,.56,4.5,0.5,0.5,1.45,0,,0.3,7.25,1,1,0']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tupleRDD = TaxiRDD.map(lambda line: line.split())\n",
    "tupleRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge',\n",
       " ',2020-01-27',\n",
       " '06:40:00,2020-01-27',\n",
       " '07:25:00,,,159,61,,19.84,40.95,2.75,0,0,6.12,,0.3,50.12,,,',\n",
       " '2,2020-01-18']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD = TaxiRDD.flatMap(lambda line: line.split())\n",
    "wordsRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2686"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2686"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD.map(lambda x: 1).reduce(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a word count on all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTaxiRDD = sc.textFile('Data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5036382"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTaxiRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5036382"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTaxiRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow taxi records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
